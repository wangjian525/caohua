{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from numpy import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow.keras import layers,datasets\n",
    "from sklearn.preprocessing import LabelEncoder,MinMaxScaler,StandardScaler\n",
    "from tensorflow import keras\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import lightgbm as lgb\n",
    "import category_encoders as ce\n",
    "from sklearn.metrics import f1_score,classification_report,roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plan_info = pd.read_csv('./ptom_third_plan.csv')\n",
    "plan_info.dropna(how='all', inplace=True, axis=1)\n",
    "plan_info.drop(['ad_start_time', 'ad_end_time', 'remark','origin'], axis=1, inplace=True)\n",
    "plan_info.dropna(subset=['ad_info'],inplace=True)\n",
    "plan_info.drop(['ad_id', 'ad_group_id', 'ad_name','media_id','plan_id','launch_op_id','bid_mode','bid_status','bid',\n",
    "                'budget_mode','budget','opt_status','status','syn_time','update_time','inventory_type'], axis=1, inplace=True)\n",
    "# 解析json\n",
    "plan_info['ad_info'] = plan_info['ad_info'].apply(json.loads)\n",
    "temp = plan_info['ad_info'].apply(pd.Series)\n",
    "plan_info = pd.concat([plan_info,temp], axis=1)\n",
    "plan_info.drop('ad_info', axis=1, inplace=True)\n",
    "temp = plan_info['audience'].apply(pd.Series)\n",
    "plan_info = pd.concat([plan_info,temp], axis=1)\n",
    "plan_info.drop('audience', axis=1, inplace=True)\n",
    "temp = plan_info['action'].apply(pd.Series)\n",
    "plan_info = pd.concat([plan_info,temp], axis=1)\n",
    "plan_info.drop('action', axis=1, inplace=True)\n",
    "plan_info.dropna(how='all', inplace=True, axis=1)\n",
    "\n",
    "plan_info_2 = plan_info.copy()\n",
    "plan_info_2.drop(['game_package_batch_id','advanced_creative_type','game_package_desc','game_package_thumbnail_ids',\n",
    "               'external_url','intelligent_flow_switch','audience_package_id','union_video_type','converted_time_duration',\n",
    "               'roi_goal','device_type','deep_bid_type','auto_extend_targets'],axis=1,inplace=True)\n",
    "plan_info_2.drop(['package','open_url','ad_modify_time','deep_cpabid','download_url','download_mode','id','campaign_id',\n",
    "               'package','ad_create_time','start_time','ad_id','name','status','modify_time','advertiser_id','schedule_type','quick_app_url',\n",
    "               'end_time','convert_id','audit_reject_reason','download_type','budget_mode','bid','pricing',\n",
    "               'include_custom_actions','app_type','exclude_flow_package','aweme_fan_behaviors','business_ids','user_type',\n",
    "               'activate_type','aweme_fan_accounts','aweme_fan_categories','aweme_fans_numbers','article_category',\n",
    "                'flow_package','carrier','superior_popularity_type','device_brand','exclude_custom_actions','geolocation',\n",
    "               'opt_status','learning_phase','district'],axis=1,inplace=True)\n",
    "# 删除老版兴趣行为定向\n",
    "plan_info_2.drop(['ad_tag','interest_tags','app_behavior_target','app_category','app_ids'],axis=1,inplace=True)\n",
    "# 删除老版兴趣行为定向\n",
    "plan_info_2.drop(['retargeting_tags'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_info = pd.read_csv('./image_info.csv')\n",
    "# image_info.drop('create_time',axis=1,inplace=True)\n",
    "# image_info.rename(columns={'create_time':'create_date'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(plan_info_2,image_info,on=['channel_id','source_id'],how='left')\n",
    "df.dropna(subset=['image_id'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "launch_report = pd.read_csv('./launch_report.csv',usecols=['tdate','channel_id', 'source_id', 'amount',\n",
    "       'create_role_num', 'pay_role_user_num', 'new_role_money'])\n",
    "launch_report.sort_values(by='tdate',inplace=True)\n",
    "launch_report.drop_duplicates(subset=['channel_id','source_id'],keep='first',inplace=True)\n",
    "df = pd.merge(df, launch_report,on=['channel_id','source_id'],how='left')\n",
    "df.drop(df[df['tdate'].isna()].index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['create_role_pay_cost'] = df.apply(lambda x:np.inf if x.pay_role_user_num==0 else x.amount/x.pay_role_user_num, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['platform'] = df['platform'].astype(str)\n",
    "df['platform'] = df['platform'].map({\"['ANDROID']\":1,\"['IOS']\":2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df.apply(lambda x: 1 if (x.pay_role_user_num>0)&(x.amount>=500) else 0,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ad_account_id'] = df['ad_account_id'].astype('int')\n",
    "df['image_id'] = df['image_id'].astype('int')\n",
    "df.rename(columns={'tdate':'create_date'},inplace=True)\n",
    "# df['create_date'] = pd.to_datetime(df['create_date']).dt.date\n",
    "df['create_date'] = pd.to_datetime(df['create_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取image不同窗口期的运营数据\n",
    "im_train_data_1 = pd.read_csv('./im_data/train_data_1.csv')\n",
    "# im_train_data_2 = pd.read_csv('./im_data/train_data_2.csv')\n",
    "im_train_data_3 = pd.read_csv('./im_data/train_data_3.csv')\n",
    "# im_train_data_4 = pd.read_csv('./im_data/train_data_4.csv')\n",
    "im_train_data_5 = pd.read_csv('./im_data/train_data_5.csv')\n",
    "# im_train_data_6 = pd.read_csv('./im_data/train_data_6.csv')\n",
    "im_train_data_7 = pd.read_csv('./im_data/train_data_7.csv')\n",
    "# im_train_data_10 = pd.read_csv('./im_data/train_data_10.csv')\n",
    "for i in [1,3,5,7]:\n",
    "    exec(\"im_train_data_%d.drop(['label_ids_%d'],axis=1,inplace=True)\"%(i,i))\n",
    "    exec(\"im_train_data_%d.rename(columns={'model_run_datetime_%d':'create_date','image_id_%d':'image_id'},inplace=True)\"%(i,i,i))\n",
    "    exec(\"im_train_data_%d['image_id'] = im_train_data_%d['image_id'].astype('int')\"%(i,i))\n",
    "    exec(\"im_train_data_%d['create_date'] = pd.to_datetime(im_train_data_%d['create_date'])\"%(i,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_date(df,col):\n",
    "    result_df = pd.DataFrame()\n",
    "    for im_id in df[col].unique():\n",
    "        temp = df[df[col]==im_id]\n",
    "        im_date = temp['create_date'].values\n",
    "        all_date = pd.date_range(temp['create_date'].min()- pd.DateOffset(days=1),temp['create_date'].max(),freq='D')\n",
    "        new_date = pd.DataFrame(np.setdiff1d(all_date,im_date),columns=['create_date'])\n",
    "        new_date[col]=im_id\n",
    "        temp = pd.concat([temp,new_date])\n",
    "        temp.sort_values(by='create_date',inplace=True)\n",
    "        temp = temp.reset_index(drop=True)\n",
    "        temp = temp.fillna(method='ffill')\n",
    "        temp = temp.fillna(method='bfill')\n",
    "        result_df = result_df.append(temp)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_train_data_1 = fill_date(im_train_data_1,col='image_id')\n",
    "im_train_data_3 = fill_date(im_train_data_3,col='image_id')\n",
    "im_train_data_5 = fill_date(im_train_data_5,col='image_id')\n",
    "im_train_data_7 = fill_date(im_train_data_7,col='image_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, im_train_data_1, on=['image_id','create_date'],how='left', validate='many_to_one')\n",
    "# df = pd.merge(df, im_train_data_2, on=['image_id','create_date'],how='left', validate='many_to_one')\n",
    "df = pd.merge(df, im_train_data_3, on=['image_id','create_date'],how='left', validate='many_to_one')\n",
    "# df = pd.merge(df, im_train_data_4, on=['image_id','create_date'],how='left', validate='many_to_one')\n",
    "df = pd.merge(df, im_train_data_5, on=['image_id','create_date'],how='left', validate='many_to_one')\n",
    "# df = pd.merge(df, im_train_data_6, on=['image_id','create_date'],how='left', validate='many_to_one')\n",
    "df = pd.merge(df, im_train_data_7, on=['image_id','create_date'],how='left', validate='many_to_one')\n",
    "# df = pd.merge(df, im_train_data_10, on=['image_id','create_date'],how='left', validate='many_to_one')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取ad不同窗口期的运营数据\n",
    "ad_train_data_1 = pd.read_csv('./ad_data/train_data_1.csv')\n",
    "# ad_train_data_2 = pd.read_csv('./ad_data/train_data_2.csv')\n",
    "ad_train_data_3 = pd.read_csv('./ad_data/train_data_3.csv')\n",
    "# ad_train_data_4 = pd.read_csv('./ad_data/train_data_4.csv')\n",
    "ad_train_data_5 = pd.read_csv('./ad_data/train_data_5.csv')\n",
    "# ad_train_data_6 = pd.read_csv('./ad_data/train_data_6.csv')\n",
    "ad_train_data_7 = pd.read_csv('./ad_data/train_data_7.csv')\n",
    "# ad_train_data_10 = pd.read_csv('./ad_data/train_data_10.csv')\n",
    "for i in [1,3,5,7]:\n",
    "    exec(\"ad_train_data_%d.rename(columns={'model_run_datetime':'create_date'},inplace=True)\"%(i))\n",
    "    exec(\"ad_train_data_%d['ad_account_id'] = ad_train_data_%d['ad_account_id'].astype('int')\"%(i,i))\n",
    "    exec(\"ad_train_data_%d['create_date'] = pd.to_datetime(ad_train_data_%d['create_date'])\"%(i,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_train_data_1 = fill_date(ad_train_data_1,col='ad_account_id')\n",
    "ad_train_data_3 = fill_date(ad_train_data_3,col='ad_account_id')\n",
    "ad_train_data_5 = fill_date(ad_train_data_5,col='ad_account_id')\n",
    "ad_train_data_7 = fill_date(ad_train_data_7,col='ad_account_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, ad_train_data_1, on=['ad_account_id','create_date'],how='left', validate='many_to_one')\n",
    "# df = pd.merge(df, ad_train_data_2, on=['ad_account_id','create_date'],how='left', validate='many_to_one')\n",
    "df = pd.merge(df, ad_train_data_3, on=['ad_account_id','create_date'],how='left', validate='many_to_one')\n",
    "# df = pd.merge(df, ad_train_data_4, on=['ad_account_id','create_date'],how='left', validate='many_to_one')\n",
    "df = pd.merge(df, ad_train_data_5, on=['ad_account_id','create_date'],how='left', validate='many_to_one')\n",
    "# df = pd.merge(df, ad_train_data_6, on=['ad_account_id','create_date'],how='left', validate='many_to_one')\n",
    "df = pd.merge(df, ad_train_data_7, on=['ad_account_id','create_date'],how='left', validate='many_to_one')\n",
    "# df = pd.merge(df, ad_train_data_10, on=['ad_account_id','create_date'],how='left', validate='many_to_one')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取ad_im不同窗口期的运营数据\n",
    "ad_im_train_data_1 = pd.read_csv('./ad_im_data/train_data_1.csv')\n",
    "ad_im_train_data_2 = pd.read_csv('./ad_im_data/train_data_2.csv')\n",
    "ad_im_train_data_3 = pd.read_csv('./ad_im_data/train_data_3.csv')\n",
    "ad_im_train_data_4 = pd.read_csv('./ad_im_data/train_data_4.csv')\n",
    "ad_im_train_data_5 = pd.read_csv('./ad_im_data/train_data_5.csv')\n",
    "ad_im_train_data_6 = pd.read_csv('./ad_im_data/train_data_6.csv')\n",
    "ad_im_train_data_7 = pd.read_csv('./ad_im_data/train_data_7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [1,2,3,4,5,6,7]: \n",
    "    exec(\"ad_im_train_data_%d.rename(columns={'model_run_datetime':'create_date','image_id_%d':'image_id'},inplace=True)\"%(i,i))\n",
    "    exec(\"ad_im_train_data_%d['image_id'] = ad_im_train_data_%d['image_id'].astype('int')\"%(i,i))\n",
    "    exec(\"ad_im_train_data_%d['ad_account_id'] = ad_im_train_data_%d['ad_account_id'].astype('int')\"%(i,i))\n",
    "    exec(\"ad_im_train_data_%d['create_date'] = pd.to_datetime(ad_im_train_data_%d['create_date'])\"%(i,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, ad_im_train_data_1, on=['ad_account_id','image_id','create_date'],how='left', validate='many_to_one')\n",
    "df = pd.merge(df, ad_im_train_data_2, on=['ad_account_id','image_id','create_date'],how='left', validate='many_to_one')\n",
    "df = pd.merge(df, ad_im_train_data_3, on=['ad_account_id','image_id','create_date'],how='left', validate='many_to_one')\n",
    "df = pd.merge(df, ad_im_train_data_4, on=['ad_account_id','image_id','create_date'],how='left', validate='many_to_one')\n",
    "df = pd.merge(df, ad_im_train_data_5, on=['ad_account_id','image_id','create_date'],how='left', validate='many_to_one')\n",
    "df = pd.merge(df, ad_im_train_data_6, on=['ad_account_id','image_id','create_date'],how='left', validate='many_to_one')\n",
    "df = pd.merge(df, ad_im_train_data_7, on=['ad_account_id','image_id','create_date'],how='left', validate='many_to_one')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_col = ['im_create_role_cost_1','im_create_role_cost_3',\n",
    "            'im_create_role_cost_5','im_create_role_cost_7',\n",
    "            'ad_create_role_cost_1','ad_create_role_cost_3',\n",
    "            'ad_create_role_cost_5','ad_create_role_cost_7']\n",
    "for col in cost_col:\n",
    "    df[col] = df[col].apply(lambda x:x if x>0 else np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['create_time'] = pd.to_datetime(df['create_time'])\n",
    "df['ad_im_sort_id'] = df.groupby(['ad_account_id','image_id'])['create_time'].rank()\n",
    "df['ad_game_sort_id'] = df.groupby(['ad_account_id','game_id'])['create_time'].rank()\n",
    "df['im_ad_sort_id'] = df.groupby(['image_id','ad_account_id'])['create_time'].rank()\n",
    "df['weekday'] = df['create_time'].dt.weekday\n",
    "df['month'] = df['create_time'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays = ['2020-01-01','2020-01-24','2020-01-25','2020-01-26','2020-01-27','2020-01-28',\n",
    "           '2020-01-29','2020-01-30','2020-01-31','2020-04-04','2020-04-05','2020-04-06',\n",
    "           '2020-05-01','2020-05-02','2020-05-03','2020-05-04','2020-05-05','2020-06-25',\n",
    "           '2020-06-26','2020-06-27','2020-10-01','2020-10-02','2020-10-03','2020-10-04','2020-10-05',\n",
    "           '2020-10-06','2020-10-07','2020-10-08','2021-01-01','2021-01-02','2021-01-03','2021-02-11',\n",
    "           '2021-02-12','2021-02-13','2021-02-14','2021-02-15','2021-02-16','2021-02-17']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['create_date'] = pd.to_datetime(df['create_time']).dt.date\n",
    "df['create_date'] = df['create_date'].astype(str)\n",
    "df['is_holiday'] = (df.create_date.isin(holidays)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['interest_words','action_words','budget','bid2','cpa_bid'],axis=1,inplace=True)\n",
    "\n",
    "df.drop(['create_role_num','amount','pay_role_user_num','new_role_money','create_role_pay_cost'],axis=1,inplace=True)\n",
    "df.drop(['channel_id','source_id','create_date'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对列表内容进行编码降维\n",
    "def get_mutil_feature(data):\n",
    "    cols = ['inventory_type','age','city','retargeting_tags_include','retargeting_tags_exclude','ac','interest_categories',\n",
    "       'action_scene','action_categories']\n",
    "    for col in cols:\n",
    "        if col in ['inventory_type','age']:\n",
    "            data[col] = data[col].apply(lambda x:x if x==x else [])\n",
    "            data = data.join(data[col].str.join('|').str.get_dummies().add_prefix(col+'_'))\n",
    "            data.drop(col,axis=1,inplace=True)\n",
    "        elif col in ['city','retargeting_tags_include','retargeting_tags_exclude','interest_categories','action_categories']:\n",
    "            data[col] = data[col].apply(lambda x:x if x==x else [])\n",
    "            data[col]=data[col].apply(lambda x:[str(i) for i in x])\n",
    "            temp = data[col].str.join('|').str.get_dummies()\n",
    "    #         print(temp.shape[1])\n",
    "            pca = PCA(n_components=0.9)\n",
    "            temp = pca.fit_transform(temp.values)\n",
    "            temp = pd.DataFrame(temp,columns = [col+str(i) for i in range(temp.shape[1])])\n",
    "    #         print(temp.shape[1])\n",
    "            data = data.join(temp)\n",
    "            del temp\n",
    "            data.drop(col,axis=1,inplace=True)\n",
    "        else:\n",
    "            data[col] = data[col].apply(lambda x:x if x==x else [])\n",
    "            data[col]=data[col].apply(lambda x:[str(i) for i in x])\n",
    "            data = data.join(data[col].str.join('|').str.get_dummies().add_prefix(col+'_'))\n",
    "            data.drop(col,axis=1,inplace=True)\n",
    "    \n",
    "    gc.collect()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df = get_mutil_feature(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['ad_account_id','game_id','schedule_time','delivery_range','flow_control_mode',\n",
    "            'smart_bid_type','hide_if_converted','gender','location_type','launch_price','retargeting_type',\n",
    "            'android_osv','ios_osv','interest_action_mode',\n",
    "            'action_days','image_id','label_ids']\n",
    "for col in cat_cols:\n",
    "    df[col] = df[col].astype(str)\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_cols = ['ad_account_id','game_id','inventory_type','schedule_time','delivery_range','flow_control_mode',\n",
    "#             'smart_bid_type','hide_if_converted','age','gender','city','location_type','platform','launch_price','retargeting_type',\n",
    "#             'retargeting_tags_include','retargeting_tags_exclude','ac','android_osv','ios_osv','interest_action_mode',\n",
    "#             'interest_categories','action_categories','action_days','action_scene','image_id','label_ids']\n",
    "# for col in cat_cols:\n",
    "#     df[col] = df[col].astype(str)\n",
    "#     le = LabelEncoder()\n",
    "#     df[col] = le.fit_transform(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = df[df['create_time'] >='2020-11-15']\n",
    "train_data = df[df['create_time'] <'2020-11-15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.drop(['create_time'],axis=1,inplace=True)\n",
    "train_data.drop(['create_time'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data, test_data = train_test_split(df, test_size=0.25)\n",
    "target = train_data['label']\n",
    "features = train_data.drop(['label'], axis=1)\n",
    "X_val, x_test, Y_val, y_test = train_test_split(features,target, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不调参\n",
    "params = {\n",
    "\"objective\": \"binary\",\n",
    "\"boosting_type\": \"gbdt\",\n",
    "\"learning_rate\": 0.01,\n",
    "\"max_depth\":8,\n",
    "\"num_leaves\":55,\n",
    "\"max_bin\":255,\n",
    "\"min_data_in_leaf\":101,\n",
    "\"min_child_samples\":15,\n",
    "\"feature_fraction\": 0.5,\n",
    "\"bagging_fraction\":0.6,\n",
    "\"bagging_freq\":20,\n",
    "\"lambda_l1\":1e-05,\n",
    "\"lambda_l2\":0,\n",
    "\"min_split_gain\": 0.0,\n",
    "\"metric\": \"auc\",\n",
    "'is_unbalance':True    \n",
    "}\n",
    "\n",
    "train_data = lgb.Dataset(X_val, label=Y_val)\n",
    "val_data = lgb.Dataset(x_test, label=y_test, reference=train_data)\n",
    "lgb_b = lgb.train(params, train_data, num_boost_round=8000, early_stopping_rounds=100, valid_sets=[train_data, val_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用train_data_pay_7_test数据集进行测试\n",
    "target_test = test_data['label']\n",
    "features_test = test_data.drop(['label'], axis=1)\n",
    "y_predict = lgb_b.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y_predict)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(target_test,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(y_predict)\n",
    "s.sort_values(ascending=False).reset_index(drop=True)[int(y_predict.shape[0] *0.07)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = list(map(lambda x:1 if x>=s.sort_values(ascending=False).reset_index(drop=True)[int(y_predict.shape[0] *0.07)] else 0,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(target_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "lgb.plot_importance(lgb_b, max_num_features=20)\n",
    "plt.title('Feature Importance')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
